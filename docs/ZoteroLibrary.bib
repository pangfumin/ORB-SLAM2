0_2949NHCX 0_2T267IB7 0_5X4GXFUU 0_5ZCJ2GBQ 0_673QWX57 0_8HQVGJ2C 0_8SIXRJ9A 0_9M7ZS5KM 0_AJDDP3A8 0_BMPAAUWG 0_DKCCGKP3 0_EHFKQN9I 0_FG9GX67M 0_FW8KXI4W 0_GHUNRK34 0_MZRVPDPP 0_NCX7VI9P 0_R3SV983B 0_TSD4Z5F5

@inproceedings{burschka2004vgpsslam,
	title = {V-{GPS} ({SLAM}): {Vision}-based inertial system for mobile robots},
	volume = {1},
	shorttitle = {V-{GPS} ({SLAM})},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1307184},
	urldate = {2016-01-18},
	booktitle = {Robotics and {Automation}, 2004. {Proceedings}. {ICRA}'04. 2004 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Burschka, Darius and Hager, Gregory D.},
	year = {2004},
	pages = {409--415},
	file = {[PDF] from jhu.edu:/home/sujiwo/References/storage/TKP2QB3X/Burschka and Hager - 2004 - V-GPS (SLAM) Vision-based inertial system for mob.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/T8W6V55Z/login.html:text/html}
}
@article{faugeras1988motionand,
	title = {Motion and structure from motion in a piecewise planar environment},
	volume = {02},
	issn = {0218-0014},
	url = {http://www.worldscientific.com/doi/abs/10.1142/s0218001488000285},
	doi = {10.1142/S0218001488000285},
	abstract = {We show in this article that when the environment is piecewise linear, it provides a powerful constraint on the kind of matches that exist between two images of the scene when the camera motion is unknown. For points and lines located in the same plane, the correspondence between the two cameras is a collineation. We show that the unknowns (the camera motion and the plane equation) can be recovered, in general, from an estimate of the matrix of this collineation. The two-fold ambiguity that remains can be removed by looking at a second plane, by taking a third view of the same plane, or by using a priori knowledge about the geometry of the plane being looked at. We then show how to combine the estimation of the matrix of collineation and the obtaining of point and line matches between the two images, by a strategy of Hypothesis Prediction and Testing guided by a Kalman filter. We finally show how our approach can be used to calibrate a system of cameras.},
	number = {03},
	urldate = {2015-06-25},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Faugeras, O.d. and Lustman, F.},
	month = sep,
	year = {1988},
	pages = {485--508},
	file = {541810b70cf25ebee987ff2e.pdf:/home/sujiwo/References/storage/MBU6G5GG/541810b70cf25ebee987ff2e.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/QR6X3CHD/s0218001488000285.html:text/html}
}
@article{kato2015anopen,
	title = {An {Open} {Approach} to {Autonomous} {Vehicles}},
	volume = {35},
	issn = {0272-1732},
	doi = {10.1109/MM.2015.133},
	abstract = {Autonomous vehicles are an emerging application of automotive technology. They can recognize the scene, plan the path, and control the motion by themselves while interacting with drivers. Although they receive considerable attention, components of autonomous vehicles are not accessible to the public but instead are developed as proprietary assets. To facilitate the development of autonomous vehicles, this article introduces an open platform using commodity vehicles and sensors. Specifically, the authors present algorithms, software libraries, and datasets required for scene recognition, path planning, and vehicle control. This open platform allows researchers and developers to study the basis of autonomous vehicles, design new algorithms, and test their performance using the common interface.},
	number = {6},
	journal = {IEEE Micro},
	author = {Kato, Shinpei and Takeuchi, Eijiro and Ishiguro, Yoshio and Ninomiya, Yoshiki and Takeda, Kazuya and Hamada, Tsuyoshi},
	month = nov,
	year = {2015},
	keywords = {autonomous vehicles, Cameras, Hardware configuration, Laser radar, mobile robots, Sensors, software platforms, Three-dimensional displays},
	pages = {60--68},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/AP7XW2C8/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/sujiwo/References/storage/7NMUB7SZ/Kato et al. - 2015 - An Open Approach to Autonomous Vehicles.pdf:application/pdf}
}
@article{mur-artal2015orbslam,
	title = {{ORB}-{SLAM}: a {Versatile} and {Accurate} {Monocular} {SLAM} {System}},
	shorttitle = {{ORB}-{SLAM}},
	url = {http://arxiv.org/abs/1502.00956},
	abstract = {The gold standard method for tridimensional reconstruction and camera localization from a set of images is well known to be Bundle Adjustment (BA). Although BA was regarded for years as a costly method restricted to the offline domain, several real time algorithms based on BA flourished in the last decade. However those algorithms were limited to perform SLAM in small scenes or only Visual Odometry. In this work we built on excellent algorithms of the last years to design from scratch a Monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments, with the capability of wide baseline loop closing and relocalization, and including full automatic initialization. Our survival of the fittest approach to select the points and keyframes of the reconstruction generates a compact and trackable map that only grows if the scene content changes, enhancing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets achieving unprecedented performance with a typical localization accuracy from 0.2\% to 1\% of the trajectory dimension in scenes from a desk to several city blocks. We make public a ROS implementation.},
	urldate = {2015-05-15},
	journal = {arXiv:1502.00956 [cs]},
	author = {Mur-Artal, Raul and Montiel, J. M. M. and Tardos, Juan D.},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.00956},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {arXiv.org Snapshot:/home/sujiwo/References/storage/5N7BQWAF/1502.html:text/html;Mur-Artal et al_2015_ORB-SLAM.pdf:/home/sujiwo/References/storage/T7DCQJN7/Mur-Artal et al_2015_ORB-SLAM.pdf:application/pdf}
}
@article{williams2009acomparison,
	title = {A comparison of loop closing techniques in monocular {SLAM}},
	volume = {57},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889009000876},
	number = {12},
	urldate = {2015-10-26},
	journal = {Robotics and Autonomous Systems},
	author = {Williams, Brian and Cummins, Mark and Neira, Jos{\'e} and Newman, Paul and Reid, Ian and Tard{\'o}s, Juan},
	year = {2009},
	pages = {1188--1197},
	file = {[PDF] dari ox.ac.uk:/home/sujiwo/References/storage/NSHQHBKC/Williams et al. - 2009 - A comparison of loop closing techniques in monocul.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/MAJQQATU/S0921889009000876.html:text/html}
}
@article{szeliski1997shapeambiguities,
	title = {Shape ambiguities in structure from motion},
	volume = {19},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=589211},
	number = {5},
	urldate = {2016-01-12},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	author = {Szeliski, Richard and Kang, Sing Bing},
	year = {1997},
	pages = {506--512},
	file = {[PDF] from microsoft.com:/home/sujiwo/References/storage/NB6T4STD/Szeliski and Kang - 1997 - Shape ambiguities in structure from motion.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/EPR8H28Z/abs_all.html:text/html}
}
@inproceedings{moosmann2011velodyne,
	title = {Velodyne {SLAM}},
	doi = {10.1109/IVS.2011.5940396},
	abstract = {Estimating a vehicles' own trajectory and generating precise maps of the environment are both important tasks for intelligent vehicles. Especially for the second task laser scanners are the sensor of choice as they provide precise range measurements. This work proposes an approach for simultaneous localization and mapping (SLAM) specifically designed for the Velodyne HDL-64E laser scanner which exhibits characteristics not present in most other systems. This comprises the continuous, spinning data acquisition and the relative high sensor noise. Together, these make standard SLAM approaches generate noisy maps and inaccurate trajectories. We show that it is possible to generate precise maps and localize therein in spite of not using wheel speed sensors or other information. The presented approach is evaluated on a novel, challenging 3D data set being made publicly available.},
	booktitle = {2011 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Moosmann, F. and Stiller, C.},
	month = jun,
	year = {2011},
	keywords = {data acquisition, image colour analysis, Intelligent vehicles, Iterative closest point algorithm, Measurement by laser beam, optical scanners, path control, Path planning, Pixel, road vehicles, Simultaneous localization and mapping, SLAM (robots), Three dimensional displays, Trajectory, Vehicles, vehicle trajectory, Velodyne HDL-64E laser scanner, Velodyne SLAM},
	pages = {393--398},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/HFMX6AW9/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/sujiwo/References/storage/3BP3G9NH/Moosmann and Stiller - 2011 - Velodyne SLAM.pdf:application/pdf}
}
@inproceedings{biber2003thenormal,
	title = {The normal distributions transform: a new approach to laser scan matching},
	volume = {3},
	shorttitle = {The normal distributions transform},
	doi = {10.1109/IROS.2003.1249285},
	abstract = {Matching 2D range scans is a basic component of many localization and mapping algorithms. Most scan match algorithms require finding correspondences between the used features, i.e. points or lines. We propose an alternative representation for a range scan, the normal distributions transform. Similar to an occupancy grid, we subdivide the 2D plane into cells. To each cell, we assign a normal distribution, which locally models the probability of measuring a point. The result of the transform is a piecewise continuous and differentiable probability density, that can be used to match another scan using Newton's algorithm. Thereby, no explicit correspondences have to be established. We present the algorithm in detail and show the application to relative position tracking and simultaneous localization and map building (SLAM). First results on real data demonstrate, that the algorithm is capable to map unmodified indoor environments reliable and in real time, even without using odometry data.},
	booktitle = {2003 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}, 2003. ({IROS} 2003). {Proceedings}},
	author = {Biber, P. and Strasser, W.},
	month = oct,
	year = {2003},
	keywords = {2D range scans, differentiable probability density, Discrete transforms, Gaussian distribution, image matching, Indoor environments, Iterative closest point algorithm, Laser noise, laser scan matching, map building, mapping algorithms, mobile robots, Newton algorithm, normal distribution, normal distributions transform, odometry data, optical scanners, Paints, probability, relative position tracking, simultaneous localization, Simultaneous localization and mapping, tracking, Working environment noise},
	pages = {2743--2748 vol.3},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/B9NBKKSA/freeabs_all.html:text/html;IEEE Xplore Full Text PDF:/home/sujiwo/References/storage/N5EE7MPZ/Biber and Strasser - 2003 - The normal distributions transform a new approach.pdf:application/pdf}
}
@article{fuentes-pacheco2015visualsimultaneous,
	title = {Visual simultaneous localization and mapping: a survey},
	volume = {43},
	shorttitle = {Visual simultaneous localization and mapping},
	url = {http://link.springer.com/article/10.1007/s10462-012-9365-8},
	number = {1},
	urldate = {2015-10-26},
	journal = {Artificial Intelligence Review},
	author = {Fuentes-Pacheco, Jorge and Ruiz-Ascencio, Jos{\'e} and Rend{\'o}n-Mancha, Juan Manuel},
	year = {2015},
	pages = {55--81},
	file = {[PDF] dari researchgate.net:/home/sujiwo/References/storage/P7HUEEG6/Fuentes-Pacheco et al. - 2015 - Visual simultaneous localization and mapping a su.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/7IC7CZ4W/s10462-012-9365-8.html:text/html}
}
@article{galvez-lopez2012bagsof,
	title = {Bags of {Binary} {Words} for {Fast} {Place} {Recognition} in {Image} {Sequences}},
	volume = {28},
	issn = {1552-3098},
	doi = {10.1109/TRO.2012.2197158},
	abstract = {We propose a novel method for visual place recognition using bag of words obtained from accelerated segment test (FAST)+BRIEF features. For the first time, we build a vocabulary tree that discretizes a binary descriptor space and use the tree to speed up correspondences for geometrical verification. We present competitive results with no false positives in very different datasets, using exactly the same vocabulary and settings. The whole technique, including feature extraction, requires 22 ms/frame in a sequence with 26 300 images that is one order of magnitude faster than previous approaches.},
	number = {5},
	journal = {IEEE Transactions on Robotics},
	author = {Galvez-L{\'o}pez, D. and Tardos, J.D.},
	month = oct,
	year = {2012},
	keywords = {accelerated segment test, Bag of binary words, bags of binary words, binary descriptor space, Cameras, computer vision, dbow2, FAST{\textpm}BRIEF features, fast place recognition, feature extraction, geometrical verification, Geometry, image sequences, Indexes, mobile robots, object recognition, place recognition, Robots, Simultaneous localization and mapping, simultaneous localization and mapping (SLAM), SLAM (robots), trees (mathematics), Vectors, visual place recognition, Vocabulary, vocabulary tree},
	pages = {1188--1197},
	file = {Galvez-L{\'o}pez_Tardos_2012_Bags of Binary Words for Fast Place Recognition in Image Sequences.pdf:/home/sujiwo/References/storage/8MH44VDU/Galvez-L{\'o}pez_Tardos_2012_Bags of Binary Words for Fast Place Recognition in Image Sequences.pdf:application/pdf;IEEE Xplore Abstract Record:/home/sujiwo/References/storage/VMXP645B/articleDetails.html:text/html}
}
@article{wolcott2014visuallocalization,
	title = {Visual {Localization} within {LIDAR} {Maps} for {Automated} {Urban} {Driving}},
	url = {http://robots.engin.umich.edu/publications/rwolcott-2014a.pdf},
	urldate = {2014-10-02},
	author = {Wolcott, Ryan W. and Eustice, Ryan M.},
	year = {2014},
	file = {[PDF] dari umich.edu:/home/sujiwo/References/storage/EVCV2TNQ/Wolcott dan Eustice - Visual Localization within LIDAR Maps for Automate.pdf:application/pdf}
}
@inproceedings{takeuchi2006a3d,
	title = {A 3-{D} {Scan} {Matching} using {Improved} 3-{D} {Normal} {Distributions} {Transform} for {Mobile} {Robotic} {Mapping}},
	doi = {10.1109/IROS.2006.282246},
	abstract = {A 3D scan matching is an important component for sensor based localization and mapping by a mobile robot in natural environment. In this paper, the present authors propose a way to extend 2D normal distributions transform (NDT) scan matching method to 3D scan matching, and its improvement for faster processing time. This scan matching method divides scan into voxels, and approximates scan points in each cell into normal distribution. That matching time is O(N) with N of the number of input scan points. The authors describe in this paper, NDT for 3D scan points, its acceleration using the dual resolutions of NDT, and experiments of map building in large scale environments},
	booktitle = {2006 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Takeuchi, E. and Tsubouchi, T.},
	month = oct,
	year = {2006},
	keywords = {3D normal distributions transform, 3D scan matching method, Acceleration, Gaussian distribution, intelligent robots, Iterative algorithms, Iterative closest point algorithm, Least squares methods, mobile robotic mapping, mobile robots, normal distribution, Shape, Simultaneous localization and mapping, terrain mapping},
	pages = {3068--3073},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/EAHIPN6F/freeabs_all.html:text/html}
}
@inproceedings{lourakis2013accurate,
	title = {Accurate scale factor estimation in 3D reconstruction},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40261-6_60},
	urldate = {2016-01-11},
	booktitle = {Computer {Analysis} of {Images} and {Patterns}},
	publisher = {Springer},
	author = {Lourakis, Manolis and Zabulis, Xenophon},
	year = {2013},
	pages = {498--506},
	file = {[PDF] from psu.edu:/home/sujiwo/References/storage/7IWABMRT/Lourakis and Zabulis - 2013 - Accurate scale factor estimation in 3D reconstruct.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/2FNCCDJD/978-3-642-40261-6_60.html:text/html}
}
@article{morales2009autonomous,
	title = {Autonomous robot navigation in outdoor cluttered pedestrian walkways},
	volume = {26},
	url = {http://www.researchgate.net/profile/Y_Morales/publication/220648386_Autonomous_robot_navigation_in_outdoor_cluttered_pedestrian_walkways/links/5405f4190cf2bba34c1df22b.pdf},
	number = {8},
	urldate = {2016-01-20},
	journal = {Journal of Field Robotics},
	author = {Morales, Yoichi and Carballo, Alexander and Takeuchi, Eijiro and Aburadani, Atsushi and Tsubouchi, Takashi},
	year = {2009},
	pages = {609},
	file = {[PDF] from researchgate.net:/home/sujiwo/References/storage/C89VGNCP/Morales et al. - 2009 - Autonomous robot navigation in outdoor cluttered p.pdf:application/pdf}
}
@inproceedings{klein2007parallel,
	title = {Parallel {Tracking} and {Mapping} for {Small} {AR} {Workspaces}},
	doi = {10.1109/ISMAR.2007.4538852},
	abstract = {This paper presents a method of estimating camera pose in an unknown scene. While this has previously been attempted by adapting SLAM algorithms developed for robotic exploration, we propose a system specifically designed to track a hand-held camera in a small AR workspace. We propose to split tracking and mapping into two separate tasks, processed in parallel threads on a dual-core computer: one thread deals with the task of robustly tracking erratic hand-held motion, while the other produces a 3D map of point features from previously observed video frames. This allows the use of computationally expensive batch optimisation techniques not usually associated with real-time operation: The result is a system that produces detailed maps with thousands of landmarks which can be tracked at frame-rate, with an accuracy and robustness rivalling that of state-of-the-art model-based systems.},
	booktitle = {6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2007. {ISMAR} 2007},
	author = {Klein, G. and Murray, D.},
	month = nov,
	year = {2007},
	keywords = {Algorithm design and analysis, augmented reality, batch optimisation techniques, Cameras, Concurrent computing, hand-held camera, Handheld computers, Layout, parallel mapping, parallel tracking, robotic exploration, robot vision, Robot vision systems, Robustness, Simultaneous localization and mapping, SLAM algorithms, SLAM (robots), tracking, Yarn},
	pages = {225--234},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/GWIC2VMD/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/sujiwo/References/storage/VJWAJRHN/Klein dan Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspa.pdf:application/pdf}
}
@inproceedings{rublee2011orban,
	title = {{ORB}: {An} efficient alternative to {SIFT} or {SURF}},
	shorttitle = {{ORB}},
	doi = {10.1109/ICCV.2011.6126544},
	abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
	booktitle = {2011 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Rublee, E. and Rabaud, V. and Konolige, K. and Bradski, G.},
	month = nov,
	year = {2011},
	keywords = {binary descriptor, Boats, BRIEF, computer vision, feature matching, image matching, noise resistance, Object detection, object recognition, ORB, patch-tracking, SIFT, smart phone, SURF, tracking, transforms},
	pages = {2564--2571},
	file = {IEEE Xplore Abstract Record:/home/sujiwo/References/storage/JVW7PZ3W/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/sujiwo/References/storage/K3C6AWJ5/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:application/pdf}
}
@inproceedings{konolige2009towards,
	title = {Towards lifelong visual maps},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5354121},
	urldate = {2016-01-03},
	booktitle = {Intelligent {Robots} and {Systems}, 2009. {IROS} 2009. {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Konolige, Kurt and Bowman, James},
	year = {2009},
	pages = {1156--1163},
	file = {[PDF] from psu.edu:/home/sujiwo/References/storage/XTT7CBHR/Konolige and Bowman - 2009 - Towards lifelong visual maps.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/3G3QC8M5/login.html:text/html}
}
@incollection{engel2014lsdslam,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{LSD}-{SLAM}: {Large}-{Scale} {Direct} {Monocular} {SLAM}},
	copyright = {{\textcopyright}2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-10604-5 978-3-319-10605-2},
	shorttitle = {{LSD}-{SLAM}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10605-2_54},
	abstract = {We propose a direct (feature-less) monocular SLAM algorithm which, in contrast to current state-of-the-art regarding direct methods, allows to build large-scale, consistent maps of the environment. Along with highly accurate pose estimation based on direct image alignment, the 3D environment is reconstructed in real-time as pose-graph of keyframes with associated semi-dense depth maps. These are obtained by filtering over a large number of pixelwise small-baseline stereo comparisons. The explicitly scale-drift aware formulation allows the approach to operate on challenging sequences including large variations in scene scale. Major enablers are two key novelties: (1) a novel direct tracking method which operates on sim(3){\textbackslash}mathfrak\{sim\}(3) , thereby explicitly detecting scale-drift, and (2) an elegant probabilistic solution to include the effect of noisy depth values into tracking. The resulting direct monocular SLAM system runs in real-time on a CPU.},
	language = {en},
	number = {8690},
	urldate = {2014-12-15},
	booktitle = {Computer {Vision} {\textendash} {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Engel, Jakob and Sch{\"o}ps, Thomas and Cremers, Daniel},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	month = jan,
	year = {2014},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Graphics, Image Processing and Computer Vision, pattern recognition},
	pages = {834--849},
	file = {engel14eccv.pdf:/home/sujiwo/References/storage/CVS4AHD6/engel14eccv.pdf:application/pdf;Snapshot:/home/sujiwo/References/storage/DJVD5DXZ/978-3-319-10605-2_54.html:text/html}
}
@techreport{ohshima2008teachingplayback,
	title = {Teaching-{Playback} {Navigation} by {Vision} {Geometry} for {Tsukuba} {Challenge} 2008},
	abstract = {The paper explains author{\textquoteright}s approach for Tsukuba-Challenge 2008. The mobile robot estimates its position and posture by using a camera. The robot also takes evasive action to obstacles by using a SOKUIKI sensor. The authors are now developing "teaching-playback method" using systems explained above.},
	author = {Ohshima, Akira and Yuta, Shinichi},
	year = {2008},
	pages = {15--18}
}