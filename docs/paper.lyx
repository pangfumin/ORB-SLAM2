#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{hyperref}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Vision-based Localization and Navigation using ORB-SLAM in Tsukuba Challenge
\end_layout

\begin_layout Author
Adi Sujiwo and Eijiro Takeuchi
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Background
\end_layout

\begin_layout Standard
The importance of vision-based localization can not be understated.
\end_layout

\begin_layout Standard
To the best of our knowledge, it is the first implementation of monocular
 vision-based localization in Tsukuba Challenge.
\end_layout

\begin_layout Standard
Our primary reason for choosing ORB-SLAM is related in our work in autonomous
 vehicles, which requires localization methods using monocular camera and
 provides capability for lifelong mapping.
 
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Standard
In the Tsukuba Challenge, we would like to evaluate effectiveness of ORB-SLAM
 and compare the localization results against LIDAR-based method as ground
 truth.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Subsection
Monocular SLAM
\end_layout

\begin_layout Standard
Besides ORB-SLAM, there have been a number of monocular SLAM with complete
 public implementation.
 Of particular mention are PTAM by 
\begin_inset CommandInset citation
LatexCommand cite
key "klein2007parallel"

\end_inset

, and LSD-SLAM by 
\begin_inset CommandInset citation
LatexCommand cite
key "engel2014lsdslam"

\end_inset

.
\end_layout

\begin_layout Standard
ORB-SLAM itself was described in 
\begin_inset CommandInset citation
LatexCommand cite
key "mur-artal2015orbslam"

\end_inset

.
\end_layout

\begin_layout Subsection
Velodyne SLAM
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "moosmann2011velodyne"

\end_inset

.
\end_layout

\begin_layout Section
Strategies for Vision-based Localization
\end_layout

\begin_layout Standard
In order to provide multiple time localization, our implementation of ORB-SLAM
 consists of two parts: mapping and localization-only.
 The mapping process runs similar with original implementation, with addition
 of map storage in the end of mapping run.
 Meanwhile, the localization-only process starts with map restoration from
 data saved previously by mapping process.
 Next, localization-only proceeds similar with mapping.
 However, map modification is disabled in relocalization process.
\end_layout

\begin_layout Subsection
Description of ORB-SLAM
\end_layout

\begin_layout Standard
The ORB-SLAM main process creates an environmental map which consists of
 keyframes and map points.
 Each keyframe stores its position in ORB-SLAM coordinate and a list of
 2D feature points.
 These feature points are computed from ORB feature points in tracking subproces
s.
 
\end_layout

\begin_layout Standard
The whole ORB-SLAM process consists of three parallel threads: tracking,
 local mapping and loop closing.
 The tracking is responsible to localize the camera with every frame, and
 decides when to insert a new keyframe.
 
\end_layout

\begin_layout Subsubsection
Tracking
\end_layout

\begin_layout Subsubsection
Local Mapping
\end_layout

\begin_layout Subsubsection
Loop Closing
\end_layout

\begin_layout Subsection
Problems in Original Implementation of ORB-SLAM
\end_layout

\begin_layout Subsubsection
Scale Problem
\end_layout

\begin_layout Standard
ORB-SLAM emits localization results in its own coordinate system, which
 is not free from distortion.
 This problem is inherent in almost all vision-based localization methods.
 In some occasion, result maps may suffer heavy distance distortion, as
 illustrated below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename scale problem.svg
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
ORB-SLAM robot trajectory (top), ground truth (middle), and zoomed part
 of red square in top figure
\begin_inset CommandInset label
LatexCommand label
name "fig:ORB-SLAM-robot-trajectory"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:ORB-SLAM-robot-trajectory"

\end_inset

, it is clear that ORB-SLAM has very different trajectory shape compared
 to ground truth (trajectory generated by Velodyne SLAM at corresponding
 time).
 By zooming-in parts in red square, it is revealed that most later keyframes
 clump in a small area of the ORB-SLAM map.
\end_layout

\begin_layout Subsubsection
Sudden Vision Occlusion
\end_layout

\begin_layout Subsubsection
Delay to First Position Fix
\end_layout

\begin_layout Standard
During localization, it is vital to get position fix as early as possible,
 preferably before motion is commenced.
 However, ORB-SLAM tends to delay position fix ?
\end_layout

\begin_layout Subsection
Implementation and Modification of ORB-SLAM
\end_layout

\begin_layout Subsubsection
Augmentation of Velodyne SLAM Positioning
\end_layout

\begin_layout Standard
Scale problem can be solved if distance of two particular point in ORB-SLAM
 is known based on external reference.
 Thus, in addition to keyframe positions in ORB-SLAM, we also recorded correspon
ding poses in Velodyne SLAM coordinates.
 These poses will be useful to calculate pose correction in Localization-only
 process.
\end_layout

\begin_layout Subsubsection
Map Storage and Restoration
\end_layout

\begin_layout Standard
Map storage consists of three main parts: Keyframes, Map points (and reference
 to which keyframe they belong)
\end_layout

\begin_layout Standard
During map restoration, the system reconstructs the following data structures:
\end_layout

\begin_layout Enumerate
Keyframe list and visibility graph
\end_layout

\begin_layout Enumerate
Map point list
\end_layout

\begin_layout Enumerate
Octree of keyframe position in ORB-SLAM coordinate.
 This tree will be used for fast searching of keyframes during localization
 using augmented positioning.
\end_layout

\begin_layout Subsubsection
Localization-only Using Augmented Positioning
\end_layout

\begin_layout Standard
In the localization-only process, the system depends solely on ORB-SLAM
 method.
 Therefore, external method such as velodyne LIDAR is not required.
 However, the system modifies position value to correct distance distortion
 according to this formula:
\end_layout

\begin_layout Enumerate
Take original ORB-SLAM positioning result as 
\begin_inset Formula $P_{o}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Search the nearest keyframe from 
\begin_inset Formula $P_{o}$
\end_inset

 using previous octree.
 From here, we take the corresponding Velodyne SLAM position 
\begin_inset Formula $P_{n}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Find the previous keyframe 
\begin_inset Formula $P_{o'}$
\end_inset

 and its corresponding Velodyne SLAM position 
\begin_inset Formula $P_{n'}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Compute distance scale: 
\begin_inset Formula 
\[
s=\frac{\left\Vert P_{n'}-P_{n}\right\Vert }{\left\Vert P_{o'}-P_{o}\right\Vert }
\]

\end_inset


\end_layout

\begin_layout Enumerate
Apply distance scale to correct current position:
\begin_inset Formula 
\[
P_{c}=P_{n}+s(P_{o}-P_{o'})
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Place Recognition after Map Restoration
\end_layout

\begin_layout Standard
By default, ORB-SLAM will try to find position against last keyframe when
 it ever get lost.
 However, it is impractical after map restoration, because last keyframe
 is unknown.
 Instead, we modify ORB-SLAM to force it finding the most appropriate keyframe
 using bag-of-word method.
 Keyframe search is also applied when the system lost tracking, to ensure
 that the system always get the keyframe as basis for relocalization.
 The drawback is that keyframe search using bag-of-word is slower than tracking
 using last keyframe.
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
We generated two maps 
\end_layout

\begin_layout Subsection
Relocalisation and Tracking
\end_layout

\begin_layout Subsection
Problems
\end_layout

\begin_layout Section
Bibliography
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ZoteroLibrary"
options "ieeetr"

\end_inset


\end_layout

\end_body
\end_document
