#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{hyperref}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman times
\font_sans helvet
\font_typewriter courier
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Monocular Vision-based Localization and Navigation using ORB-SLAM in Tsukuba
 Challenge
\end_layout

\begin_layout Author
Adi Sujiwo, Eijiro Takeuchi and Tomohito Ando
\end_layout

\begin_layout Abstract
In 2015 Tsukuba Challenge, we have realized an implementation of vision-based
 localization based on ORB-SLAM.
 Our method combined mapping based on ORB-SLAM and Velodyne LIDAR SLAM,
 and utilized these maps in localization process using solely monocular
 camera.
 This approach delivered better accuracy compared to original ORB-SLAM,
 which suffers from scale ambiguities and experiences map distance distortion.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Background
\end_layout

\begin_layout Standard
The importance of vision-based localization can not be overstated.
 In applications like autonomous vehicle, this localization method will
 significantly reduce cost for manufacturer, which previously must use LIDAR-bas
ed solutions.
 However, vision-based methods are usually avoided due to inaccuracy when
 compared to LIDAR-based methods, in addition to lack of metrically correctness.
\end_layout

\begin_layout Standard
To the best of our knowledge, it is the first implementation of monocular
 vision-based localization in Tsukuba Challenge.
 Previous methods for localization usually employs LIDAR-based methods,
 either 2D or 3D.
\end_layout

\begin_layout Standard
Our primary reason for choosing ORB-SLAM is related in our work in autonomous
 vehicles, which requires localization methods using monocular camera and
 provides capability for lifelong mapping.
 
\end_layout

\begin_layout Standard
Our challenge ...
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Standard
In the Tsukuba Challenge, we would like to evaluate effectiveness of ORB-SLAM
 and compare the localization results against LIDAR-based method as ground
 truth.
\end_layout

\begin_layout Section
Related Works
\end_layout

\begin_layout Subsection
Monocular SLAM
\end_layout

\begin_layout Standard
Besides ORB-SLAM, there have been a number of monocular SLAM with complete
 public implementation.
 Of particular mention are PTAM by 
\begin_inset CommandInset citation
LatexCommand cite
key "klein2007parallel"

\end_inset

, and LSD-SLAM by 
\begin_inset CommandInset citation
LatexCommand cite
key "engel2014lsdslam"

\end_inset

.
\end_layout

\begin_layout Standard
ORB-SLAM itself was described in 
\begin_inset CommandInset citation
LatexCommand cite
key "mur-artal2015orbslam"

\end_inset

.
\end_layout

\begin_layout Standard
All monocular SLAM methods are based on 3D reconstruction from multiple
 view of scenes 
\begin_inset CommandInset citation
LatexCommand cite
key "fuentes-pacheco2015visualsimultaneous"

\end_inset

, which in turn are based on Structure from Motion.
 As stated in 
\begin_inset CommandInset citation
LatexCommand cite
key "szeliski1997shapeambiguities"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "lourakis2013accurate"

\end_inset

, all monocular structure from motion methods inherit common scale ambiguities,
 which consists in the fact that the recovered 3D structures and camera
 motion are defined up to an unknown scale factor which cannot be determined
 from image streams alone.
 This is because if the scene and camera are scaled together, this change
 will not be indistinguishable in the captured images.
\end_layout

\begin_layout Subsection
Velodyne SLAM
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "moosmann2011velodyne"

\end_inset

.
\end_layout

\begin_layout Section
Strategies for Vision-based Localization
\end_layout

\begin_layout Standard
In order to provide multiple time localization, our implementation of ORB-SLAM
 consists of two parts: mapping and localization-only.
 The mapping process runs similar with original implementation, with addition
 of map storage in the end of mapping run.
 Meanwhile, the localization-only process starts with map restoration from
 data saved previously by mapping process.
 Next, localization-only proceeds similar with mapping.
 However, map modification is disabled in relocalization process.
\end_layout

\begin_layout Subsection
Description of ORB-SLAM
\end_layout

\begin_layout Standard
The ORB-SLAM main process creates an environmental map which consists of
 keyframes and map points.
 Each keyframe stores its position in ORB-SLAM coordinate and a list of
 2D feature points.
 These feature points are computed from ORB feature points in tracking subproces
s.
 
\end_layout

\begin_layout Standard
The whole ORB-SLAM process consists of three parallel threads: tracking,
 local mapping and loop closing.
 The tracking is responsible to localize the camera with every frame, and
 decides when to insert a new keyframe.
 
\end_layout

\begin_layout Subsubsection
Feature Detection
\end_layout

\begin_layout Standard
The first step in all 3D reconstruction is to find feature points in each
 frame.
 ORB-SLAM uses ORB (Oriented FAST, Rotated BRIEF) described in 
\begin_inset CommandInset citation
LatexCommand cite
key "rublee2011orban"

\end_inset

.
 This detector has advantages such as faster computation and lower storage
 requirement (each descriptor only needs 32 bytes), in addition to resistance
 against rotation and noise.
 By default, number of extracted ORB points is fixed at 1000.
 However, we found that increasing this number up to 2500 gives many benefits,
 including faster map initialization and resistance against image flaws
 such as partial occlusion and lens flares.
\end_layout

\begin_layout Subsubsection
Map Initialization
\end_layout

\begin_layout Standard
The goal of the map initialization is to compute the relative pose between
 two frames to triangulate an initial set of map points
\begin_inset CommandInset citation
LatexCommand cite
key "mur-artal2015orbslam"

\end_inset

, which then will be used for keyframe tracking.
 ORB-SLAM uses combination of homography and fundamental matrices inside
 RANSAC scheme in order to build motion and structure recovery as described
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "faugeras1988motionand"

\end_inset

.
 When this stage is succesful, the system will have an initial set of keyframes
 and map points for which tracking may proceed.
 However, some times tracking fails shortly after initial map is built.
 When this is the case, initial map is deleted and initialization process
 will start over.
\end_layout

\begin_layout Subsubsection
Tracking
\end_layout

\begin_layout Standard
The tracking thread is responsible for providing localization and map building.
 After ORB corners are detected, 
\end_layout

\begin_layout Subsubsection
Local Mapping
\end_layout

\begin_layout Subsubsection
Loop Closing
\end_layout

\begin_layout Subsection
Problems in Original Implementation of ORB-SLAM
\end_layout

\begin_layout Subsubsection
Scale Problem
\end_layout

\begin_layout Standard
ORB-SLAM emits localization results in its own coordinate system, which
 is not free from distortion.
 This problem is inherent in almost all vision-based localization methods.
 In some occasion, result maps may suffer heavy deformation, as illustrated
 below.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename scale problem.svg
	lyxscale 30
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
ORB-SLAM robot trajectory (top), ground truth (middle), and zoomed part
 of red square in top figure
\begin_inset CommandInset label
LatexCommand label
name "fig:ORB-SLAM-robot-trajectory"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
From 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:ORB-SLAM-robot-trajectory"

\end_inset

, it is clear that ORB-SLAM has very different trajectory shape compared
 to ground truth (trajectory generated by Velodyne SLAM at corresponding
 time).
 By zooming-in parts in red square, it is revealed that most later keyframes
 clump in a small area of the ORB-SLAM map.
\end_layout

\begin_layout Subsubsection
Sudden Vision Occlusion
\end_layout

\begin_layout Standard
Any disturbances in camera vision that make it unable to view previously
 tracked feature points may cause ORB-SLAM to lost tracking.
 These include vision occlusion on behalf of camera and sudden rotation
 of the robot.
 The default behaviour of ORB-SLAM to reacquire tracking after lost event
 is by performing relocalization from last keyframe (i.e.
 guess pose from last known position).
 However, this prevent the system to reacquire position especially when
 the robot never reverses motion, and contrary to described behaviour in
 original paper of ORB-SLAM.
 Our solution is to force relocalization by searching all keyframes in database.
\end_layout

\begin_layout Subsubsection
Delay to First Position Fix
\end_layout

\begin_layout Standard
During localization, it is vital to get position fix as early as possible,
 preferably before motion is commenced.
 However, ORB-SLAM tends to delay position fix ?
\end_layout

\begin_layout Subsection
Implementation and Modification of ORB-SLAM
\end_layout

\begin_layout Subsubsection
Augmentation of Velodyne SLAM Positioning
\end_layout

\begin_layout Standard
Scale problem can be solved if distance of two particular point in ORB-SLAM
 is known based on external reference.
 Thus, in addition to keyframe positions in ORB-SLAM, we also recorded correspon
ding poses in Velodyne SLAM coordinates.
 These poses will be useful to calculate pose correction in Localization-only
 process.
\end_layout

\begin_layout Subsubsection
Map Storage and Restoration
\end_layout

\begin_layout Standard
Map storage consists of three main parts: Keyframes, Map points (and reference
 to which keyframe they belong)
\end_layout

\begin_layout Standard
During map restoration, the system reconstructs the following data structures:
\end_layout

\begin_layout Enumerate
Keyframe list and visibility graph.
 The visibility graph is relation between feature points and map points
 at which they represent, and their visibilities in keyframes.
\end_layout

\begin_layout Enumerate
Map point list
\end_layout

\begin_layout Enumerate
Octree of keyframe position in ORB-SLAM coordinate.
 This tree will be used for fast searching of keyframes during localization
 using augmented positioning.
\end_layout

\begin_layout Subsubsection
Localization-only Using Augmented Positioning
\end_layout

\begin_layout Standard
In the localization-only process, the system depends solely on ORB-SLAM
 method.
 Therefore, external methods such as velodyne LIDAR are not required.
 However, the system modifies position value to correct distance distortion
 according to this formula:
\end_layout

\begin_layout Enumerate
Take original ORB-SLAM positioning result as 
\begin_inset Formula $P_{o}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Search the nearest keyframe from 
\begin_inset Formula $P_{o}$
\end_inset

 using previous octree.
 From here, we take the corresponding Velodyne SLAM position 
\begin_inset Formula $P_{n}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Find the previous keyframe 
\begin_inset Formula $P_{o'}$
\end_inset

 and its corresponding Velodyne SLAM position 
\begin_inset Formula $P_{n'}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Compute distance scale: 
\begin_inset Formula 
\[
s=\frac{\left\Vert P_{n'}-P_{n}\right\Vert }{\left\Vert P_{o'}-P_{o}\right\Vert }
\]

\end_inset


\end_layout

\begin_layout Enumerate
Apply distance scale to correct current position:
\begin_inset Formula 
\[
P_{c}=P_{n}+s(P_{o}-P_{o'})
\]

\end_inset


\end_layout

\begin_layout Standard
In localization-only process, map modification is disabled.
\end_layout

\begin_layout Subsubsection
Place Recognition after Map Restoration
\end_layout

\begin_layout Standard
By default, ORB-SLAM will try to find position against last keyframe when
 it ever get lost.
 However, it is impractical after map restoration, because last keyframe
 is unknown.
 Instead, we modify ORB-SLAM to force it finding the most appropriate keyframe
 using bag-of-word method.
 Keyframe search is also applied when the system lost tracking, to ensure
 that the system always get the keyframe as basis for relocalization.
 The drawback is that keyframe search using bag-of-word is slower than tracking
 using last keyframe.
\end_layout

\begin_layout Subsubsection
Using Multiple Maps
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
We performed four runs of robot by tracing the trajectory mandated by Tsukuba
 Challenge committee.
 In each run, we recorded camera images and performed localization using
 Velodyne LIDAR using two different computers due to high computational
 requirement.
 Clocks of both computers were not synchronized.
 From these runs, we created two maps for localization process.
 Velodyne LIDAR results would be used as ground truth for comparison.
 To reduce computation, camera resolution was reduced to 
\begin_inset Formula $800\times600$
\end_inset

 before processing.
\end_layout

\begin_layout Standard
Two runs were chosen as material for mapping with consideration that those
 runs spanned longest runs without any vision occlusion.
 However, in both run path loop were not executed.
 Therefore, we were not able to evaluate loop closing capability of ORB-SLAM.
 Next, we performed localization test in two runs using both maps.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename map 1 & 3.svg
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Maps (M1) and (M2) of Tsukuba Challenge generated by ORB-SLAM.
 (M1) exhibits heavy deformation towards later parts of trajectory, while
 (M2) has less distortion.
 Both maps are not metrically correct.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ndt-map-3.svg
	lyxscale 70
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Ground truth from Velodyne SLAM.
 In both runs for mapping, real trajectories of robot were about the same.
 This map is metrically correct.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Map Saving and Restoration
\end_layout

\begin_layout Standard
In our experience, map saving and restoration does not affect ORB-SLAM performan
ce.
 In addition, the system gains useful capability: map building can now be
 done incrementally, using same location in different time.
 This is useful for example, to build lifelong map in different situation
 such as weather and day/night.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename partial map.png
	lyxscale 70
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Partial map being built after loading
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
First Position Fix
\end_layout

\begin_layout Standard
To get initial position fix, ORB-SLAM performs keyframe search based on
 appearances of feature points.
 Search may returns more than one candidates, on which they will be evaluated
 on reprojection error basis.
 Only one candidate is accepted, and it must have at least 15 map points
 that match with feature points in current frame.
 In the evaluation run however, the system was slow to get the fix due to
 insufficient matches.
 One possible correction to fasten initial fix is by increasing number of
 feature points from ORB computation.
 However, this approach heavily slows down the search process, and does
 not always correlate to faster fix.
\end_layout

\begin_layout Standard
Map initialization is also another problem.
 During experiment, we found that initialization will succeed (and not getting
 false initialization) whenever robot is moved, either rotation or translation.
\end_layout

\begin_layout Subsection
Tracking and Relocalization
\end_layout

\begin_layout Standard
During our experiment, we found that ORB-SLAM is resistant against occasional
 and partial vision occlusion.
 Total occlusion however, may cause the system to miss tracking and difficult
 to recover.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename orb-1.svg
	lyxscale 40
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Using Map (M1)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename orb-2.svg
	lyxscale 40
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Using Map (M2)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Localization Using Maps (M1) and (M2)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Loop Closing
\end_layout

\begin_layout Standard
The Tsukuba Challenge track features some areas that are ideal to test loop
 closing subsystem of any SLAM system.
 However, ORB-SLAM had not able to perform loop closing when they were supposed
 to take place.
 An important area is the Oshimizu park subtrack, that features a small
 roundabout with far buildings as background.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename loop closing failure.png
	lyxscale 70
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
One place where loop closing failed to take place.
 Image contrast has been adjusted to lighten dark areas.
 Notice that most ORB points (green) fell in the background cloud.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Accuracy of Corrected Localization
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename path inspection.svg
	lyxscale 70
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Visual comparison of Modified ORB-SLAM trajectory against ground truth (blue
 curve).
 Map 1 result is depicted in green, while map 2 is red.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure above depicts a turning situation continued by straight path.
 In the turning, modified ORB-SLAM shows deviations compared to ground truth,
 while straight path has less deviation.
 It is also clear that different maps give different results, despite running
 in the exact same path and time.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Errors of Modified ORB-SLAM compared to ground truth
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Problems
\end_layout

\begin_layout Subsubsection
Lost Tracking
\end_layout

\begin_layout Subsubsection
Incomplete Maps
\end_layout

\begin_layout Standard
None of the maps that are complete (i.e.
 provide keyframes that cover the whole ground truth).
\end_layout

\begin_layout Section
Bibliography
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ZoteroLibrary"
options "ieeetr"

\end_inset


\end_layout

\end_body
\end_document
